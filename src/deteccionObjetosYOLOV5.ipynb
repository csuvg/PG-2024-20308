{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformaci칩n del data set para alimentar modelo YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Pillow\n",
    "# !pip install rawpy\n",
    "# !pip install imageio\n",
    "# !pip install yolov5\n",
    "# !pip install torch torchvision\n",
    "# !pip install numpy opencv-python\n",
    "# !pip install roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace la carga del modelo de YOLOv5 con el uso de la herramiento torch hub para as칤 lograr tener el modelo pre entrenado cargado y listo para ser utilizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/marcojurado/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 游 2024-8-22 Python-3.10.5 torch-2.4.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir las categorias que nos van a ser de interes para detecci칩n de objetos. Estos son los que para esta investigaci칩n y desarrollo vamos a estar trabajando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_of_interest = ['stop', 'traffic light']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funci칩n para detecci칩n y recortar los objetos detectados mediante su bounding box para lograr obtener las imagenes resultantes de este proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = 'datasets/dataset_secundario'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los folders de output que vamos a estar utilizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = 'datasets/cropped_and_labeled'\n",
    "images_folder = os.path.join(output_folder, 'images')\n",
    "labels_folder = os.path.join(output_folder, 'labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos si existe la ruta o si no la creamos para guardar las imagenes cropped obtenidas de YOLOv5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(images_folder):\n",
    "    os.makedirs(images_folder)\n",
    "\n",
    "if not os.path.exists(labels_folder):\n",
    "    os.makedirs(labels_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline de YOLOv5 donde vamos a estar procesando las imagenes y obteniendo los objetos que sean detectados por el mismo modelo. Aqui tambien generamos la label para la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detected_labels1 = []\n",
    "\n",
    "# # Primera versi칩n de detecci칩n de objetos con YOLO\n",
    "# def detect_crop_and_label_v1(input_folder, images_folder, labels_folder):\n",
    "#     images = [os.path.join(input_folder, file) for file in os.listdir(input_folder) if file.endswith('.jpg')]\n",
    "\n",
    "#     for img_path in images:\n",
    "#         img = cv2.imread(img_path)\n",
    "#         results = model(img)\n",
    "\n",
    "#         for i, (*xyxy, conf, cls) in enumerate(results.xyxy[0]):\n",
    "#             x1, y1, x2, y2 = map(int, xyxy)\n",
    "#             cropped_img = img[y1:y2, x1:x2]\n",
    "\n",
    "#             label = int(cls)  # Obtener la clase predicha (label)\n",
    "#             label_name = results.names[label]  # Obtener el nombre de la clase\n",
    "\n",
    "#             # Guardar la imagen recortada en la subcarpeta de im치genes\n",
    "#             output_filename = f\"{os.path.basename(img_path).split('.')[0]}_{label_name}_{i}.jpg\"\n",
    "#             output_path = os.path.join(images_folder, output_filename)\n",
    "#             cv2.imwrite(output_path, cropped_img)\n",
    "#             print(f\"Imagen recortada guardada en: {output_path}\")\n",
    "\n",
    "#             # Guardar la etiqueta en un archivo de texto en la subcarpeta de etiquetas\n",
    "#             label_filename = f\"{os.path.basename(img_path).split('.')[0]}_{label_name}_{i}.txt\"\n",
    "#             label_path = os.path.join(labels_folder, label_filename)\n",
    "#             with open(label_path, 'w') as label_file:\n",
    "#                 label_file.write(label_name)\n",
    "#             print(f\"Etiqueta guardada en: {label_path}\")\n",
    "\n",
    "#             detected_labels1.append(label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect_crop_and_label_v1(input_folder, output_folder, labels_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Etiquetas detectadas durante la ejecuci칩n:\")\n",
    "# print(set(detected_labels1))  # Mostrar solo etiquetas 칰nicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def detect_crop_and_label_v2(input_folder, images_folder, labels_folder):\n",
    "#     images = [os.path.join(input_folder, file) for file in os.listdir(input_folder) if file.endswith('.jpg')]\n",
    "\n",
    "#     for img_path in images:\n",
    "#         img = cv2.imread(img_path)\n",
    "#         results = model(img)\n",
    "\n",
    "#         for i, (*xyxy, conf, cls) in enumerate(results.xyxy[0]):\n",
    "#             label = int(cls)  # Obtener la clase predicha (label)\n",
    "#             label_name = results.names[label]  # Obtener el nombre de la clase\n",
    "\n",
    "#             # Guardar la etiqueta en un archivo de texto en la subcarpeta de etiquetas\n",
    "#             label_filename = f\"{os.path.basename(img_path).split('.')[0]}_{label_name}_{i}.txt\"\n",
    "#             label_path = os.path.join(labels_folder, label_filename)\n",
    "#             with open(label_path, 'w') as label_file:\n",
    "#                 label_file.write(label_name)\n",
    "#             # print(f\"Etiqueta guardada en: {label_path}\")\n",
    "\n",
    "#             detected_labels.append(label_name)\n",
    "\n",
    "#             if label_name in classes_of_interest:\n",
    "#                 x1, y1, x2, y2 = map(int, xyxy)\n",
    "#                 cropped_img = img[y1:y2, x1:x2]\n",
    "\n",
    "#                 # Guardar la imagen recortada en la subcarpeta de im치genes\n",
    "#                 output_filename = f\"{os.path.basename(img_path).split('.')[0]}_{label_name}_{i}.jpg\"\n",
    "#                 output_path = os.path.join(images_folder, output_filename)\n",
    "#                 cv2.imwrite(output_path, cropped_img)\n",
    "#                 # print(f\"Imagen recortada guardada en: {output_path}\")\n",
    "\n",
    "#                 # Agregar la etiqueta detectada al array\n",
    "#                 detected_labels.append(label_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir un tama침o estandarizado para las imagenes generadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el tama침o estandarizado de salida (por ejemplo, 256x256 p칤xeles)\n",
    "standard_size = (256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_labels = []\n",
    "\n",
    "def detect_crop_and_label_v3(input_folder, images_folder, labels_folder):\n",
    "    images = [os.path.join(input_folder, file) for file in os.listdir(input_folder) if file.endswith('.jpg')]\n",
    "\n",
    "    for img_path in images:\n",
    "        img = cv2.imread(img_path)\n",
    "        results = model(img)\n",
    "\n",
    "        for i, (*xyxy, conf, cls) in enumerate(results.xyxy[0]):\n",
    "            label = int(cls)  # Obtener la clase predicha (label)\n",
    "            label_name = results.names[label]  # Obtener el nombre de la clase\n",
    "\n",
    "            detected_labels.append(label_name)\n",
    "\n",
    "            if label_name in classes_of_interest:\n",
    "                # Reemplazar espacios en el nombre de la imagen\n",
    "                img_name_cleaned = os.path.basename(img_path).split('.')[0].replace(' ', '_')\n",
    "\n",
    "                # Guardar la etiqueta en un archivo de texto en la subcarpeta de etiquetas\n",
    "                label_filename = f\"{img_name_cleaned}_{label_name}_{i}.txt\".replace(' ', '_')\n",
    "                label_path = os.path.join(labels_folder, label_filename)\n",
    "                with open(label_path, 'w') as label_file:\n",
    "                    label_file.write(label_name)\n",
    "\n",
    "                x1, y1, x2, y2 = map(int, xyxy)\n",
    "                cropped_img = img[y1:y2, x1:x2]\n",
    "\n",
    "                # Redimensionar la imagen recortada al tama침o est치ndar\n",
    "                resized_img = cv2.resize(cropped_img, standard_size)\n",
    "\n",
    "                # Guardar la imagen recortada y redimensionada en la subcarpeta de im치genes\n",
    "                output_filename = f\"{img_name_cleaned}_{label_name}_{i}.jpg\".replace(' ', '_')\n",
    "                output_path = os.path.join(images_folder, output_filename)\n",
    "                cv2.imwrite(output_path, resized_img)\n",
    "                # print(f\"Imagen recortada y redimensionada guardada en: {output_path}\")\n",
    "\n",
    "    print(f\"Proceso terminado para: {input_folder}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutamos la funci칩n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder_video_1 = 'datasets/dataset_secundario/Recorriendo CIUDAD DE GUATEMALA en veh칤culo (Parte 1) - GUATEMALA 2024'\n",
    "input_folder_video_2 = 'datasets/dataset_secundario/Recorriendo CIUDAD DE GUATEMALA en veh칤culo (Parte 2) - GUATEMALA 2024'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso terminado para: datasets/dataset_secundario\n",
      "Proceso terminado para: datasets/dataset_secundario/Recorriendo CIUDAD DE GUATEMALA en veh칤culo (Parte 1) - GUATEMALA 2024\n",
      "Proceso terminado para: datasets/dataset_secundario/Recorriendo CIUDAD DE GUATEMALA en veh칤culo (Parte 2) - GUATEMALA 2024\n"
     ]
    }
   ],
   "source": [
    "detect_crop_and_label_v3(input_folder, images_folder, labels_folder)\n",
    "detect_crop_and_label_v3(input_folder_video_1, images_folder, labels_folder)\n",
    "detect_crop_and_label_v3(input_folder_video_2, images_folder, labels_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiquetas detectadas durante la ejecuci칩n:\n",
      "{'potted plant', 'elephant', 'stop sign', 'vase', 'bus', 'cell phone', 'cow', 'laptop', 'sports ball', 'skateboard', 'boat', 'person', 'book', 'bench', 'bowl', 'banana', 'bird', 'bottle', 'backpack', 'clock', 'hot dog', 'bear', 'motorcycle', 'parking meter', 'tv', 'dog', 'giraffe', 'surfboard', 'traffic light', 'chair', 'suitcase', 'car', 'train', 'truck', 'umbrella', 'kite', 'keyboard', 'toilet', 'cup', 'fire hydrant', 'bicycle', 'cake', 'handbag', 'horse', 'airplane'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Etiquetas detectadas durante la ejecuci칩n:\")\n",
    "print(set(detected_labels))  # Mostrar solo etiquetas 칰nicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Posible mejora:</b> torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Posible mejora:</b> Guardar imagenes en un formato de csv donde sea imagen, label, ruta. Para mejor eficiencia de manejo de espacio y tama침o de archivos.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Posible mejora:</b> Fine tunning de YOLO.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
