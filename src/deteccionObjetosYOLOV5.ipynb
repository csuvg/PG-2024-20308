{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformación del data set para alimentar modelo YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Pillow\n",
    "# !pip install rawpy\n",
    "# !pip install imageio\n",
    "# !pip install yolov5\n",
    "# !pip install torch torchvision\n",
    "# !pip install numpy opencv-python\n",
    "# !pip install roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace la carga del modelo de YOLOv5 con el uso de la herramiento torch hub para así lograr tener el modelo pre entrenado cargado y listo para ser utilizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/marcojurado/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 🚀 2024-8-22 Python-3.10.5 torch-2.4.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir las categorias que nos van a ser de interes para detección de objetos. Estos son los que para esta investigación y desarrollo vamos a estar trabajando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_of_interest = ['stop', 'traffic light']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para detección y recortar los objetos detectados mediante su bounding box para lograr obtener las imagenes resultantes de este proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = 'datasets/dataset_secundario'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los folders de output que vamos a estar utilizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = 'datasets/cropped_and_labeled'\n",
    "images_folder = os.path.join(output_folder, 'images')\n",
    "labels_folder = os.path.join(output_folder, 'labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos si existe la ruta o si no la creamos para guardar las imagenes cropped obtenidas de YOLOv5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(images_folder):\n",
    "    os.makedirs(images_folder)\n",
    "\n",
    "if not os.path.exists(labels_folder):\n",
    "    os.makedirs(labels_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline de YOLOv5 donde vamos a estar procesando las imagenes y obteniendo los objetos que sean detectados por el mismo modelo. Aqui tambien generamos la label para la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detected_labels1 = []\n",
    "\n",
    "# # Primera versión de detección de objetos con YOLO\n",
    "# def detect_crop_and_label_v1(input_folder, images_folder, labels_folder):\n",
    "#     images = [os.path.join(input_folder, file) for file in os.listdir(input_folder) if file.endswith('.jpg')]\n",
    "\n",
    "#     for img_path in images:\n",
    "#         img = cv2.imread(img_path)\n",
    "#         results = model(img)\n",
    "\n",
    "#         for i, (*xyxy, conf, cls) in enumerate(results.xyxy[0]):\n",
    "#             x1, y1, x2, y2 = map(int, xyxy)\n",
    "#             cropped_img = img[y1:y2, x1:x2]\n",
    "\n",
    "#             label = int(cls)  # Obtener la clase predicha (label)\n",
    "#             label_name = results.names[label]  # Obtener el nombre de la clase\n",
    "\n",
    "#             # Guardar la imagen recortada en la subcarpeta de imágenes\n",
    "#             output_filename = f\"{os.path.basename(img_path).split('.')[0]}_{label_name}_{i}.jpg\"\n",
    "#             output_path = os.path.join(images_folder, output_filename)\n",
    "#             cv2.imwrite(output_path, cropped_img)\n",
    "#             print(f\"Imagen recortada guardada en: {output_path}\")\n",
    "\n",
    "#             # Guardar la etiqueta en un archivo de texto en la subcarpeta de etiquetas\n",
    "#             label_filename = f\"{os.path.basename(img_path).split('.')[0]}_{label_name}_{i}.txt\"\n",
    "#             label_path = os.path.join(labels_folder, label_filename)\n",
    "#             with open(label_path, 'w') as label_file:\n",
    "#                 label_file.write(label_name)\n",
    "#             print(f\"Etiqueta guardada en: {label_path}\")\n",
    "\n",
    "#             detected_labels1.append(label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect_crop_and_label_v1(input_folder, output_folder, labels_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Etiquetas detectadas durante la ejecución:\")\n",
    "# print(set(detected_labels1))  # Mostrar solo etiquetas únicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def detect_crop_and_label_v2(input_folder, images_folder, labels_folder):\n",
    "#     images = [os.path.join(input_folder, file) for file in os.listdir(input_folder) if file.endswith('.jpg')]\n",
    "\n",
    "#     for img_path in images:\n",
    "#         img = cv2.imread(img_path)\n",
    "#         results = model(img)\n",
    "\n",
    "#         for i, (*xyxy, conf, cls) in enumerate(results.xyxy[0]):\n",
    "#             label = int(cls)  # Obtener la clase predicha (label)\n",
    "#             label_name = results.names[label]  # Obtener el nombre de la clase\n",
    "\n",
    "#             # Guardar la etiqueta en un archivo de texto en la subcarpeta de etiquetas\n",
    "#             label_filename = f\"{os.path.basename(img_path).split('.')[0]}_{label_name}_{i}.txt\"\n",
    "#             label_path = os.path.join(labels_folder, label_filename)\n",
    "#             with open(label_path, 'w') as label_file:\n",
    "#                 label_file.write(label_name)\n",
    "#             # print(f\"Etiqueta guardada en: {label_path}\")\n",
    "\n",
    "#             detected_labels.append(label_name)\n",
    "\n",
    "#             if label_name in classes_of_interest:\n",
    "#                 x1, y1, x2, y2 = map(int, xyxy)\n",
    "#                 cropped_img = img[y1:y2, x1:x2]\n",
    "\n",
    "#                 # Guardar la imagen recortada en la subcarpeta de imágenes\n",
    "#                 output_filename = f\"{os.path.basename(img_path).split('.')[0]}_{label_name}_{i}.jpg\"\n",
    "#                 output_path = os.path.join(images_folder, output_filename)\n",
    "#                 cv2.imwrite(output_path, cropped_img)\n",
    "#                 # print(f\"Imagen recortada guardada en: {output_path}\")\n",
    "\n",
    "#                 # Agregar la etiqueta detectada al array\n",
    "#                 detected_labels.append(label_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir un tamaño estandarizado para las imagenes generadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el tamaño estandarizado de salida (por ejemplo, 256x256 píxeles)\n",
    "standard_size = (256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_labels = []\n",
    "\n",
    "def detect_crop_and_label_v3(input_folder, images_folder, labels_folder):\n",
    "    images = [os.path.join(input_folder, file) for file in os.listdir(input_folder) if file.endswith('.jpg')]\n",
    "\n",
    "    for img_path in images:\n",
    "        img = cv2.imread(img_path)\n",
    "        results = model(img)\n",
    "\n",
    "        for i, (*xyxy, conf, cls) in enumerate(results.xyxy[0]):\n",
    "            label = int(cls)  # Obtener la clase predicha (label)\n",
    "            label_name = results.names[label]  # Obtener el nombre de la clase\n",
    "\n",
    "            detected_labels.append(label_name)\n",
    "\n",
    "            if label_name in classes_of_interest:\n",
    "                # Reemplazar espacios en el nombre de la imagen\n",
    "                img_name_cleaned = os.path.basename(img_path).split('.')[0].replace(' ', '_')\n",
    "\n",
    "                # Guardar la etiqueta en un archivo de texto en la subcarpeta de etiquetas\n",
    "                label_filename = f\"{img_name_cleaned}_{label_name}_{i}.txt\".replace(' ', '_')\n",
    "                label_path = os.path.join(labels_folder, label_filename)\n",
    "                with open(label_path, 'w') as label_file:\n",
    "                    label_file.write(label_name)\n",
    "\n",
    "                x1, y1, x2, y2 = map(int, xyxy)\n",
    "                cropped_img = img[y1:y2, x1:x2]\n",
    "\n",
    "                # Redimensionar la imagen recortada al tamaño estándar\n",
    "                resized_img = cv2.resize(cropped_img, standard_size)\n",
    "\n",
    "                # Guardar la imagen recortada y redimensionada en la subcarpeta de imágenes\n",
    "                output_filename = f\"{img_name_cleaned}_{label_name}_{i}.jpg\".replace(' ', '_')\n",
    "                output_path = os.path.join(images_folder, output_filename)\n",
    "                cv2.imwrite(output_path, resized_img)\n",
    "                # print(f\"Imagen recortada y redimensionada guardada en: {output_path}\")\n",
    "\n",
    "    print(f\"Proceso terminado para: {input_folder}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutamos la función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder_video_1 = 'datasets/dataset_secundario/Recorriendo CIUDAD DE GUATEMALA en vehículo (Parte 1) - GUATEMALA 2024'\n",
    "input_folder_video_2 = 'datasets/dataset_secundario/Recorriendo CIUDAD DE GUATEMALA en vehículo (Parte 2) - GUATEMALA 2024'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso terminado para: datasets/dataset_secundario\n",
      "Proceso terminado para: datasets/dataset_secundario/Recorriendo CIUDAD DE GUATEMALA en vehículo (Parte 1) - GUATEMALA 2024\n",
      "Proceso terminado para: datasets/dataset_secundario/Recorriendo CIUDAD DE GUATEMALA en vehículo (Parte 2) - GUATEMALA 2024\n"
     ]
    }
   ],
   "source": [
    "detect_crop_and_label_v3(input_folder, images_folder, labels_folder)\n",
    "detect_crop_and_label_v3(input_folder_video_1, images_folder, labels_folder)\n",
    "detect_crop_and_label_v3(input_folder_video_2, images_folder, labels_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiquetas detectadas durante la ejecución:\n",
      "{'potted plant', 'elephant', 'stop sign', 'vase', 'bus', 'cell phone', 'cow', 'laptop', 'sports ball', 'skateboard', 'boat', 'person', 'book', 'bench', 'bowl', 'banana', 'bird', 'bottle', 'backpack', 'clock', 'hot dog', 'bear', 'motorcycle', 'parking meter', 'tv', 'dog', 'giraffe', 'surfboard', 'traffic light', 'chair', 'suitcase', 'car', 'train', 'truck', 'umbrella', 'kite', 'keyboard', 'toilet', 'cup', 'fire hydrant', 'bicycle', 'cake', 'handbag', 'horse', 'airplane'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Etiquetas detectadas durante la ejecución:\")\n",
    "print(set(detected_labels))  # Mostrar solo etiquetas únicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Posible mejora:</b> torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Posible mejora:</b> Guardar imagenes en un formato de csv donde sea imagen, label, ruta. Para mejor eficiencia de manejo de espacio y tamaño de archivos.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Posible mejora:</b> Fine tunning de YOLO.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
